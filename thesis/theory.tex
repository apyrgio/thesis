\chapter{Necessary theoretical background}\label{ch:theory}

In this typically boring section, we will explain the basic system facilities 
and programming concepts that are used by our implementation and Archipelago in 
general. More specifically, in Section ?...

\section{Multithreading}

Mutlithreading is a programming concept that has been the subject of research 
long before the emerge of SMP
\footnote{Symmetric multiprocessing}
systems. More specifically, temporal multithreading has been introduced in the 
1950s whereas Simultaneous Multithreading (SMT), which is the current 
invocation of multithreading, was first researched by IBM in 1968\cite{mt}.

Threads and process, which are involved in multitasking, have some fundamental 
differences:

\begin{itemize}
	\item Threads are always parts of a process, whereas processes are 
		independent from each other and may only have a parent-child connection 
		between them.
	\item Forked processes have their own address space and resources, which 
		are inherited with CoW semantics. Threads, on the other hand, usually 
		share the same memory and resources with the other threads in the same 
		process.
	\item
	
\end{itemize}


\begin{enumerate}
	\item Concurrency control
	\item Challenge 2
	\item Challenge 3
\end{enumerate}

\section{Interprocess Communication - IPC}

Interprocess Communication is a concept that predates the SMP systems that we 
all use nowadays. It is a set of methods that an OS uses to allow processes and 
threads to communicate with each other. Archipelago for example, uses 
extensively IPC methods to synchronize its different components.

The full list of Linux's IPC methods is presented below:

\begin{itemize}
	\item \textbf{Signals:} they are sent to a process to notify it that an 
		event has occurred.
	\item \textbf{Pipes:} one-way channel that transfers information from 
		one process to the other.
	\item \textbf{Sockets:} bidirectional channels that can transfer 
		information between two or more processes either locally or 
		remotely through the network.
	\item \textbf{Message queues:} asynchronous communication protocol that 
		is used to exchange data packets between processes.
	\item \textbf{Semaphores:} Special purpose pipes that are used mainly 
		for process synchronization.
	\item \textbf{Shared memory:} a memory space that can be accessed and 
		edited by more than one process.
\end{itemize}

We will concentrate on the following IPC methods:
\begin{inparaenum}[i)]
\item signals,
\item sockets,
\item message queues and
\item shared memory,
\end{inparaenum}
since these are the methods that Archipelago and our implementation have used.

\subsection{Signals}

Signals are notifications that are sent to processes and can be considered as 
software interrupts. The signals' purpose is to interrupt the execution of the 
processes and inform it that an event has occurred.

Given that there more than one events and exceptions that can occur in a 
system, there are also various signals that correspond to each one of these
events. For more information about the signals that Linux supports as well as 
the conditions on which they are raised, the reader is prompted to consult the 
man pages for signal(7) or read the POSIX.1-1990, SUSv2 and POSIX.1-2001 
standards.
  
Moreover, the above standards dictate the standard behavior of a process when a 
signal is received. The standard actions that a process can take fall roughly 
in the following categories:

\begin{enumerate}
	\item ignore the signal,
	\item pause its execution,
	\item restart its execution or
	\item stop its execution and/or dump its core
\end{enumerate}

However, a process is not limited to this set of actions. It can instead do one 
of the following things, regardless of the signal that has been raised and its 
severity:

\begin{itemize}
	\item ignore the signal
	\item install a custom signal handler function, which essentially 
		passes the signal handling task to the process.
\end{itemize}

Finally, the process can block the signal, by setting the SIG\_BLOCK flag for 
this signal in the process's signal mask. This is used in Archipelago and is 
described in in Section \ref{sec:poll-archip}.

\subsection{Sockets}

Socket are a bidirectional means of sending data between processes. The 
processes can be in the same host but most commonly, they are in remote hosts 
and the data are sent over the network. Furthermore, from all the IPC methods 
that we have described above, sockets are the only method that enables remote 
communication. 

There are many socket implementations for different purposes, which are divided 
in several communication domains, most of which are rather obscure. The three 
communication domains, however, that are supported by most UNIX and UNIX-like 
operating systems are:

\begin{itemize}
	\item \textit{IPv4} domain, which allows communication between 
		processes over the Internet Protocol version 4 network.
	\item \textit{IPv6} domain, which allows communication between 
		processes over the Internet Protocol version 6 network.
	\item \textit{UNIX} domain, which allows communication between 
		processes in the same host
\end{itemize}

The above three communication domains are further divided in two types, based 
on the transport layer protocol that they use.

\begin{itemize}
	\item \textit{Stream sockets}, which use the Transmission Control 
		Protocol (TCP) or Stream Control Transmission Protocol (SCTP),
	\item \textit{Datagram sockets}, which use the User Datagram Protocol 
		(UDP),
\end{itemize}

The TCP/UDP protocols are only one layer out of the four layers that the TCP/IP 
protocol suite defines, and we will explain them in detail in the following 
sections. Although a thorough explanation of the TCP/IP protocol is out of the 
scope of this thesis and is not needed to understand the following sections, we 
will mention some of its most important aspects for the sake of completeness.

The TCP/IP protocol suite is the basis for the World Wide Internet and the most 
used form of networking. It specifies all the stages of the data processing 
that need to happen in various levels and entities, such as operating systems, 
network cards, routers etc. in order to connect two machines over the network.  
For this reason, the data that are sent are encapsulated in layers, which can 
be seen in Figure \ref{fig:data-encapsulation.pdf}.

\diagram{Data encapsulation for a UDP packet}{data-encapsulation.pdf}

We now continue with an presentation of TCP and UDP protocols.

\subsubsection{TCP}

The Transmission Control Protocol is connection-oriented, i.e. it provides 
unique connection between two sockets, and has the following key features:

\begin{description}
	\item[Reliability] The data will arrive to the receiver with no packet 
		loss, or they will not arrive at all. In the latter case, the 
		receiver may receive sparious packets but it will not 
		acknowledge them until it has received all of them.
	\item[Ordered transfer] The data will arrive in the same order that 
		they were sent.
	\item[Error-checking] The data are checksummed to allow the receiving 
		end to check if there was any data corruption.
	\item[Rate-limiting] When the receiver accepts packets with slower rate 
		than the sender, the sender will adjust its rate to ensure 
		packet delivery and less congestion.
	\item[Byte-stream] The data that are sent do not have a boundary.
\end{description}

\subsubsection{UDP}

The User Datagram Protocol on the other hand has far less restrictions than 
TCP. First, it is connectionless, meaning that the socket can receive requests 
from anyone. Second, it provides no guarantees about the delivery of the 
messages. Third, the messages can arrive in other order than the one they were 
sent. Fourth, there is no rate-limiting, meaning that the congestion control 
must be handled in the application level. Finally, it sends datagrams instead 
of bytes, which have definite boundaries.

Although there might seem that there is no reason for one to choose the 
unreliable UDP protocol, the lack of the TCP overhead makes it an ideal choice 
for applications that value speed over packet loss.

\subsection{Shared memory}

When two or more processes share the same memory segment, they can exchange 
data by placing it in a region of the segment. The data then becomes instantly 
visible to the other processes too, since their page-table entries for this 
segment point to the same RAM pages.

The way shared memory is created is analogous to a disk file creation:

\begin{enumerate}
	\item The process uses \texttt{shm\_open()}, instead of a regular 
		\texttt{open()}, in order to create a new file in /dev/shm or 
		open an existing one.
	\item Then, in both cases, it can use \texttt{ftruncate()}, which 
		resizes the file to the desirable size.
\end{enumerate}

At this point, the process is allowed to seek into the file and write to it. In 
the shared memory case however, it can also use \texttt{mmap()}, to map this 
file to its address space. There are two types on mapping:

\begin{itemize}
	\item \textit{Private mapping}, in which case the mapping contents will 
		not be visible to other processes that have mapped the same 
		file and
	\item \textit{Shared mapping}, in which case the mapping contents will 
		be visible to all processes that map this file and changes to 
		the mapping will be propagated to the file.
\end{itemize}

Finally, an issue with mappings is that the start of the shared memory is not 
always mapped in the same virtual address for all processes. For this reason, 
when processes want to share data, they should not pass direct pointers to 
them, but relative pointers (i.e. offsets) from the start of the segment, which 
are common for all processes and can be translated to the correct direct 
pointers.

\section{Concurrency control}

% Taken from wikipedia

Three concepts for locking:

\begin{enumerate}
	\item Lock overhead
	\item Lock contention
	\item Deadlocking
\end{enumerate}

\section{Page cache}

Maybe say how linux handles cachiong?

\section{Networking}

Explain TCP/UDP, sockets, polling
