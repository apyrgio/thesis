\chapter{Tiered Storage}\label{ch:tiering}

In this chapter we will discuss the challenges of today's data storage and how 
tiered storage helps in mitigating costs and increasing performance. Moreover, 
we present the current solutions for tiered storage and we evaluate if they can 
be used in conjunction with Archipelago.

\section{Theoretical Background or What is Tiered Storage}

From the genesis of the PC in ? every component was pushed to its limits to 
become as fast as possible. Take for example the CPU chip. The CPU clock is 
blabal and speed of light means 10cm. Has the same happened with disk

\subsection{Caching}

In caching, there are usually the following two policies:

\begin{itemize}
	\item Write-through:
		This policy bla bla bla
	\item Write-back:
		This policy blu blu blu
\end{itemize}

\subsubsection{Eviction}

Caching generally means that you project a large address space of a slow medium 
to the smaller address space of a faster medium. That means that not everything 
can be cached as there is no 1:1 mapping. So, when a cache reaches its maximum 
capacity, it must evict one of its entries

And the big question now arises: which entry?

This is a very old and well documented problem that still troubles the research 
community. It was first faced when creating hardware caches (the L1, L2 CPU 
caches we are familiar with). In 1966, Lazlo Belady proved that the best 
strategy is to evict the entry that is going to be used more later on in the 
future\cite{Belady}.  However, the clairvoyance needed for this strategy was a 
little difficult to implement, so we had to resort to one of the following, 
well-known strategies:

% Mention ehcache approach: 
% http://ehcache.org/documentation/apis/cache-eviction-algorithms
%
% Also look at the following papers
%L. Belady, “A Study of Replacement Algorithms for a
%Virtual-Storage Computer,” IBM Systems Journal, vol.5,
%no.2, pp.78-101, 1966.
\begin{itemize}
	\item \textbf{Random:} Simply, a randomly chosen entry is evicted. This 
		strategy, although it seems simplistic at first, is sometimes chosen 
		due to the ease and speed of each. It is preferred in random workloads 
		where getting fast free space for an entry is more important than the 
		entry that will be evicted.
	\item \textbf{FIFO (First-In-First-Out):} The entry that was first inserted 
		will also be the first to evict. This is also a very simplistic 
		approach as well as easy and fast. Interestingly, although it would 
		seem to produce better results than Random eviction, it is rarely used 
		though, since it assumes that cache entries are used only once, which 
		is not common in real-life situations.
	\item \textbf{LRU (Least-Recently-Used)}
	\item \textbf{LFU (Least-Frequently-Used)}
\end{itemize}

Choosing the LRU strategy is usually a no-brainer. Not only does it 
\textit{seem} more optimal than the other algorithms, but it has also been 
proven, using a Bayesian statistic model, that no other algorithm that tracks 
the last K references to an entry can be more optimal.
%Also, check out this paper:
%An optimality proof of the LRU-K page replacement algorithm
%that proves that no algorithm that keeps track of the K most recent references 
%for a page can be more optimal than LRU.



\section{Comparison between existing methodologies}

\subsection{Block-devices}

There have been many block device tiers that have been built


\subsubsection{Dm-cache/Flashcache/Bcache}

Bcache has been designed by Kent Overstreet since 2011 and has been included in 
the Linux kernel since the May of 2013.

Bcache allows to use one or more fast mediums as a cache for slower ones. The 
prerequisite is that both mediums must be block devices. Bcache targets the SSD  
as the fast medium and has been built around it:

\begin{enumerate}
	\item It goes to great lengths to ensure that data are written in erase 
		block size granularity.
	\item It
\end{enumerate}

has been designed with the SSD in mind, and is stacked block device driver that 
has a block device as its backend, which is commonly a συστάδα of hard disks

\subsection{Key-value store}

\subsubsection{Memcached}

\subsection{NoSQL Databases}

\subsubsection{Couchbase}

\subsubsection{Redis}

\subsection{Summary}





