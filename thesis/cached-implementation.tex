\chapter{Implementation of cached}\label{ch:cached-implementation}

In the previous chapter, we have discussed in length the design of cached and 
its components. In this chapter, we will present how the above design has been
implemented. To aid us in this task, we will use code snippets from cached and 
xcache and we will comment where necessary.

More specifically, Section \ref{sec:xcache-imp} provides implementation 
information for xcache, the main cached component. Next, section 
\ref{sec:cached-imp} presents the actual implementation of cached, showcasing 
the structures and functions used.

\section{Implementation of xcache}\label{sec:xcache-imp}

\subsection{xcache initialization}

In order to use xcache, the peer must first initialize an xcache structure 
using xcache\_init, which can be seen in Listing \ref{lst:xcache-init.h}.

\ccode{\texttt{xcache\_init definition}}{xcache-init.h}

xcache\_init requests the following information from the peer:

\begin{description}
	\item[cache:] Simply, an allocated xcache struct
	\item[xcache\_size:] The number of objects xcache will index
	\item[ops:] The trigger functions for xcache's event hooks
	\item[flags:] Optional flags that tune the following two things:
		\begin{enumerate}
			\item The LRU algorithm. For the cached implementation, 
				we use the O(1) LRU, but xcache also allows to 
				use two more LRU algorithms, a binary heap 
				(O(log(N))) or an LRU array (O(N)).
			\item The usage of the hash table for evicted entries.  
				Although our cached implementation relies 
				heavily on it, this does not account for all 
				the other peers that use xcache and by default 
				is turned off.
		\end{enumerate}
	\item[priv:] A pointer (void *) to a structure that will be returned when 
		an event hook is triggered. As most priv fields, it is irrelevant to 
		the xcache struct and relevant only to the top caller. We 
		initialize it with the peer struct.
\end{description}

The purpose of xcache\_init is to process the above data, populate the xcache 
struct and create the necessary entities, such as the hash table, the cache 
entries etc. On Listing \ref{lst:xcache-struct.h}, we can view the xcache 
struct and its respective fields.

\ccode{Main \xcache struct}{xcache-struct.h}

Each of the above \xcache struct fields serves a design feature that has 
already been discussed in Section \ref{sec:xcache-design}. In the following 
sections, we will revisit these design features and present their 
implementation.

\subsection{Cache entry preallocation}

When xcache is initialized, it preallocates the necessary cache entries. The 
relevant fields of the xcache structure for this purpose can be seen in Listing 
\ref{lst:xcache-prealloc.h}.

\ccode{\xcache struct fields for preallocated entries}{xcache-prealloc.h}

The \textbf{size} field is the number of entries. The \textbf{free\_nodes} is a 
stack where all entry indexes are initially pushed and subsequently popped when 
a new entry is inserted. Finally, \textbf{nodes} is the space allocated for the 
cache entries and where the entry indexes point to.

Moreover, the definition of the \texttt{xcache entry} struct is shown in 
Listing \ref{lst:xcache-entry.h}.

\ccode{\texttt{xcache entry} struct}{xcache-entry.h}

We will comment briefly on the relevant cache entry fields for this section, 
which can be seen in Listing \ref{lst:xcache-entry-prealloc.h}. The rest of the 
fields will be discussed in the following sections.

\ccode{\texttt{xcache entry} fields, relevant for 
	preallocation}{xcache-entry-prealloc.h}

The description of the fields follows:

\begin{description}
	\item[ref] The reference count of the entry, initially set to zero.
	\item[state] The state of the entry. It can either be ACTIVE or EVICTED and 
		is initially set to the first.
	\item[name] The name of the entry. Since we cannot know its length 
		beforehand, we allocate as much space as possible by our segment, 
		typically 256 characters. During initialization, the entry name is 
		cleared out of junk values.
	\item[h] The entry's index.
	\item[priv] The private contents of the cache entry. On initialization, the 
		cache node creation hook is triggered and cached initializes the 
		private contents of cache entry with its data (more on the Section ?)
\end{description}

\begin{comment}
	The rest willwhaLet's start by listing what \texttt{xcache entry} 
	consists of.  First of all, it must have a name.  Since we preallocate 
	the entries and cannot know in runtime their length, we must allocate 
	as much space as possible. The \texttt{char name[XSEG\_MAX\_TARGETLEN + 
		1]} field, which is 256 characters long, is long enough to hold the 
	target's name.  Also, as we have mentioned in Section 
	\ref{sec:entry-prealloc-design}, xcache must be agnostic of the cache 
	contents.  To this end, we use the generic \texttt{void *priv} field as 
	a pointer to the actual entry content.  The rest of the fields will be 
	explained in the following chapters.

	Let's continue now with the fields of Listing \ref{lst:xcache-prealloc.h}.  
	Since we preallocate the entries using \texttt{malloc}, they take up a 
	contiguous space in memory.  The start of this space is the where the 
	\texttt{*nodes} field points to. The \texttt{free\_nodes} field works similarly 
	to the free\_entries field in Section \ref{sec:get-req-archip} i.e. it is a 
	stack where indexes to unused nodes are pushed. These indexes will be seen in 
	various code excerpts in this chapter and have a specific name, 
	\texttt{xcache\_handler}\footnote{\#define xcache\_handler uint64\_t}.
\end{comment}

\subsection{Cache entry initialization}

Before a peer can index a new entry, it must first allocate it from the cache 
entry pool and then initialize it. xcache has a special function for this 
purpose which can be seen in Listing \ref{lst:xcache-alloc-init.c}

\ccode{Cache entry allocation/initialization function}{xcache-alloc-init.c}

This function attempts to claim a cache entry from the \texttt{free\_nodes}.  
Then it initializes it with the name given by the peer. Moreover, it triggers 
the cache entry initialization hook which cached uses to further initialize the 
entry.

An added benefit of this function is that it doesn't need to acquire the cache 
lock, so it does not slow down the indexing functions that rely on that look.

\subsection{Cache entry indexing}

This is the core feature of xcache. In Listing \ref{lst:xcache-index.h}, we 
present the fields of xcache struct that are relevant to the indexing task.

\ccode{xcache struct fields for entry indexing}{xcache-index.h}

As we have mentioned in Section \ref{sec:xcache-index-design}, we utilize two 
hash tables, one for the cached entries and one for the evicted entries. These 
hash tables can be accessed from the \texttt{xcache struct} and are the 
\texttt{*entries} and \texttt{*rm\_entries} respectively.

More importantly, in Listing \ref{lst:xcache-index.c} we can see the functions 
that are related to indexing and \xcache exposes to the peer:

\ccode{Indexing functions}{xcache-index.c}

All of these functions need a pointer to the \xcache struct. Also, they need to 
acquire the cache\_lock and insert specifically needs to acquire the rm\_lock 
too, in order to check in the rm\_entries.  Here's a brief description of them:

\begin{description}
	\item[xcache\_lookup:]
		Takes the target's name as an argument and searches for it in 
		cache.\\
		Returns on failure: NoEntry\footnote{\#define NoEntry 
			(xcache\_handler)-1}\\
		Returns on success: the requested handler.\\
		\textbf{Note:} Looks only in \texttt{entries}.
	\item[xcache\_insert:]
		Takes the handler of an allocated entry as an argument and uses 
		it to index that entry.\\
		Returns on failure: NoEntry.\\
		Returns on success:
		\begin{inparaenum}[i)]
		\item the same handler or,
		\item if the same entry already exists in cache, the handler of that 
			entry.
		\end{inparaenum}\\
		\textbf{Note:} It looks up first if the entry exist in 
		\texttt{entries} or \texttt{rm\_entries}. The later case can 
		lead to re-insertions.
		\begin{comment}
			Probably not needed
		\item[xcache\_remove:]
			Takes the handler of an allocated entry as an argument and uses 
			it to remove that entry.\\
			Returns on failure: -1.
			Returns on success: 0.
			\textbf{Note:} Removes entries only from \texttt{entries} hash 
			table.
		\end{comment}
\end{description}

Moreover, we show in Listing \ref{lst:xcache-entry-index.h} the cache entry 
struct fields related to indexing and comment on how they are used by each 
function.

\ccode{xcache entry struct relevant indexing}{xcache-entry-index.h}

The commentary on the above fields follows:

\begin{description}
	\item[ref:] The reference counter of an object is increased on lookups 
		and inserts, since it is essentially referenced in these 
		operations.
	\item[state:] The state of an object is already ACTIVE for lookup 
		operations (or else lookup will fail). For insertions and 
		reinsertions, it is manually set to ACTIVE.
	\item[older/younger]: These fields show the neighbors of the entry in 
		the LRU queue. The LRU queue is sorted by reference time order, 
		so the neighbors are essentially the entries that have been 
		referenced right before and right after our entry.
\end{description}

\subsection{Entry eviction}\label{xcache-evict-imp}

The relevant fields for this purpose can be seen in code listing 
\ref{lst:xcache-evict.h}

\ccode{\xcache struct fields for eviction}{xcache-evict.h}

As we have mentioned in Section \ref{sec:xcache-evict-design}, we resort to 
eviction when the cache is full and new entries can't be inserted. This entry 
is the Least Recently Used entry. The code doubly-linked list that we maintain 
for this end can be seen below:

\ccode{Doubly-linked LRU list}{xcache-dlist.h}

The last entry of the list (oldest) is usually the LRU. When an object is 
referenced, it can be instantly transferred to the head of the list (MRU), 
since we know its position via the hash table (alternatively, we would need to 
search all entries, which would require O(N) time).

Another feature of this LRU queue is that it doesn't require timestamps, so we 
can avoid the unnecessary system call.

Finally, when a cache entry is evicted from the hash table, it triggers the 
cache entry eviction hook.

\begin{comment}
\begin{itemize}
	\item Insert a new entry to the LRU list
	\item Evict the LRU entry
	\item Update an entry's access time (i.e. mark it as MRU)
	\item Remove an arbitrary entry
\end{itemize}

Lets explain these fields a bit:

\begin{description}
	\item[lru:] Obviously, it's the least recently used entry. It can be 
		considered as the one end of the doubly linked list.
	\item[mru:] The entry that has just been used. It can be considered as 
		the other end of the doubly-linked list
	\item[younger:] This entry-specific field points to an entry used right 
		after our entry was used.
	\item[older:] Same as "younger", it points to the entry that has been 
		used right before our entry was used.
\end{description}

Finally, as we have explained in Section \ref{sec:xcache-evict-design}, the 
eviction internals should normally not bother the user. However, if the user 
wants to, \xcache exposes the following functions:

\begin{description}
	\item[xcache\_evict\_lru:] The name says it all, it evicts the recently 
		used item.
	\item[xcache\_peek\_and\_get\_lru:] This function allows the user to 
		atomically take a peek on the Least Recently Used entry and also 
		update its refcount.
\end{description}
\end{comment}

\subsection{Concurrency control}\label{sec:conc-imp}

\paragraph{Locking}\label{par:lock}

\paragraph{Reference counting}\label{par:refcount-imp}

The refcount model in xcache should be familiar to most people:

% Turn this to figure
\begin{itemize}
	\item When an entry is inserted in cache, the cache holds a reference 
		for it (ref = 1).
	\item Whenever a new lookup for this cache entry succeeds, the reference 
		is increased by 1 (ref++)
	\item When the request that has issued the lookup has finished with an 
		entry, the reference is decreased by 1. (ref--)
	\item When a cache entry is evicted by cache, the its ref is decreased 
		by 1. (ref--)
\end{itemize}

Some common refcount cases are:

\begin{itemize}
	\item active entry with pending jobs (ref > 1)
	\item active entry with no pending jobs (ref = 1)
	\item evicted entry with pending jobs (ref > 0)
	\item evicted entry with no pending jobs (ref = 0)
\end{itemize}

\begin{table}[tbp]
	\centering
	\begin{tabular}{ | l | l | }
		\hline
		Case & Refcount \\ \hline \hline
		active entry with pending jobs & ref > 1 \\ \hline
		active entry with no pending jobs & ref = 1 \\ \hline
		evicted entry with pending jobs & ref > 0 \\ \hline
		evicted entry with no pending jobs & ref = 0 \\ \hline
	\end{tabular}
	\caption{Reference counting of xcache}
	\label{tab:refcount}
\end{table}

and, as always, the entry is freed only when its ref = 0.

\subsection{Event hooks}

The hooks that xcache provides to users are:

\begin{itemize}
	\item on\_ init: called on cache entry initialization.
	\item on\_put: called when the last reference to the cache entry is put
	\item on\_evict: called when a cache entry is evicted.
	\item on\_node\_init: called on initial node preparation.
	\item post\_evict: called after an eviction has occurred, with cache  
		lock held.
	\item on\_free: called when a cache entry is freed.
	\item on\_finalize: called to hint the user that the cache entry's ref 
		has dropped to zero.
	\item on\_reinsert: called when a cache entry has been in cache
\end{itemize}


\section{Implementation of cached}\label{sec:cached-imp}

The cached structure is the following:

\ccode{Main cached struct}{cached.h}

We will briefly comment on the less important entries:

\begin{description}
	\item[*cache:]
		This is the connection between cached and xcache. The xcache struct is 
		stored here.
	\item[total\_size:]
		T
\end{description}

and the cached entries are the following

\ccode{Cahed entry struct}{ce.h}

\section{Bucket pool}

And the bucket implementation is the following:

\ccode{Bucket implementation}{bucket.h}

\subsection{Bucket/Object states}

Every object has a state, which is set atomically by threads. The state list is
the following:

\begin{itemize}
	\item READY: the object is ready to be used
	\item FLUSHING: the object is flushing its dirty buckets
	\item DELETING: there is a delete request that has been sent to the 
		blocker for this object
	\item INVALIDATED: the object has been deleted
	\item FAILED: something went very wrong with this object
\end{itemize}

Also, object buckets have their own states too. These are divided in allocation 
states:

\begin{itemize}
	\item FREE: the bucket has not been touched or has been flushed
	\item CLAIMED: the bucket has been claimed
\end{itemize}

and data states:

\begin{itemize}
	\item INVALID: the same as empty
	\item LOADING: there is a pending read to blocker for this bucket
	\item VALID: the bucket is clean and can be read
	\item DIRTY: the bucket can be read but its contents have not been
		written to the underlying storage
	\item WRITING: there is a pending write to blocker for this bucket
\end{itemize}

Also, for cios we have the following:

\begin{itemize}
	\item FAILED: at least one of the cio request(s) has failed
	\item ACCEPTED: normal mode
	\item READING: at least one of the cio request(s) is pending a read
	\item WRITING: at least one of the cio request(s) is pending a write
	\item SERVED: all requests have been served
\end{itemize}


Finally, for every object there are bucket state counters, which are increased/
decreased when a bucket state is changed. These counters give us an O(1)
glimpse to the bucket states of an object.


