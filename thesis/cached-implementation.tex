\chapter{Implementation of cached}\label{ch:cached-implementation}

In the previous chapter, we have discussed in length the design of cached and 
its components. In this chapter we will present how the above design has been
implemented. To aid us in this task, we will use code snippets from cached and 
xcache and we will comment them appropriately.

More specifically, Sections ? - ? provide implementation information for the 
components of cached, as described in Chapter ?. Next, section ? presents the 
actual initialization and blabla operations using excerpts from the code.

\section{Implementation of xcache}

We begin with the implementation of xcache.  In this section, we describe how 
we implemented the design concept of section \ref{sec:xcache-design}. The main 
\xcache structure is the following:

\ccode{Main \xcache struct}{xcache-struct.h}

Each of the above \xcache struct fields serves a design purpose.
Let's see which fields help in what:

\subsection{Entry Preallocation}

The relevant fields for this purpose can be seen in the following code listing:

\ccode{\xcache struct fields for preallocated entries}{xcache-prealloc.h}

and the definition of the \texttt{xcache entry} struct which shows up in 
\texttt{xcache} struct can be seen below:

\ccode{\texttt{xcache entry} struct}{xcache-entry.h}

Let's start by listing what \texttt{xcache entry} consists of. First of all, it 
must have a name. Since we preallocate the entries and cannot know in runtime 
their length, we must allocate as much space as possible. The \texttt{char 
	name[XSEG\_MAX\_TARGETLEN + 1]} field, which is 256 characters long, is 
long enough to hold the target's name. Also, as we have mentioned in Section 
\ref{sec:entry-prealloc-design}, xcache must be agnostic of the cache contents.  
To this end, we use the generic \texttt{void *priv} field as a pointer to the 
actual entry content. The rest of the fields will be explained in the following 
chapters.

Let's continue now with the fields of Listing \ref{lst:xcache-prealloc.h}.  
Since we preallocate the entries using \texttt{malloc}, they take up a 
contiguous space in memory.  The start of this space is the where the 
\texttt{*nodes} field points to. The \texttt{free\_nodes} field works similarly 
to the free\_entries field in Section \ref{sec:get-req-archip} i.e. it is a 
stack where indexes to unused nodes are pushed. These indexes will be seen in 
various code excerpts in this chapter and have a specific name, 
\texttt{xcache\_handler}\footnote{\#define xcache\_handler uint64\_t}.

\subsection{Entry Indexing}

The relevant fields for this purpose can be seen in the following code listing:

\ccode{xcache struct fields for entry indexing}{xcache-index.h}

As we have mentioned in Section \ref{sec:xcache-index-design}, we utilize two 
hash tables, one for the cached entries and one for the former cached entries 
(or evicted entries or removed entries). These hash tables can be accessed from 
the \texttt{xcache struct} and are \texttt{*entries} and \texttt{*rm\_entries} 
respectively.

These are the functions which are related to indexing and \xcache exposes to the 
peer function:

\ccode{Indexing functions}{xcache-index.c}

All of these function need a pointer to the \xcache struct. Here's a brief 
description of them:

\begin{description}
	\item[xcache\_lookup:]
		Takes the target's name as an argument and searches for it in 
		cache.\\
		Returns on failure: NoEntry\footnote{\#define NoEntry 
			(xcache\_handler)-1}\\
		Returns on success: the requested handler.\\
		\textbf{Note:} Looks only in \texttt{entries}.
	\item[xcache\_insert:]
		Takes the handler of an allocated entry as an argument and uses 
		it to index that entry.\\
		Returns on failure: NoEntry.
		Returns on success:
		\begin{inparaenum}[\itshape a\upshape)]
		\item the same handler or
		\item another one, if this entry already exists in cache.
		\end{inparaenum}
		\textbf{Note:} It looks up first if the entry exist in 
		\texttt{entries} or \texttt{rm\_entries}. The later case can 
		lead to re-insertions.
	\item[xcache\_remove:]
		Takes the handler of an allocated entry as an argument and uses 
		it to remove that entry.\\
		Returns on failure: -1.
		Returns on success: 0.
		\textbf{Note:} Removes entries only from \texttt{entries} hash 
		table.
	\item[xcache\_invalidate:]
		An \texttt{xcache\_remove} spin-off. Takes the name of the entry 
		as an argument, looks it up and then removes it
		Returns on failure: -1.
		Returns on success: 0.
		\textbf{Note:} Unlike remove, entries can either be on 
		\texttt{entries} or \texttt{rm\_entries} hash table.
\end{description}

\subsection{Entry eviction}\label{xcache-evict-imp}

The relevant fields for this purpose can be seen in the following code listing:

\ccode{\xcache struct fields for eviction}{xcache-evict.h}

As we have mentioned in Section \ref{sec:xcache-evict-design}, we resort to 
eviction when the cache is full and new entries can't be inserted. This entry is 
the Least Recently Used entry. The doubly-linked list we maintain for this end 
can be seen below:

\ccode{Doubly-linked LRU list}{xcache-dlist.h}

We have done so by using a doubly linked list that keeps the cache entries 
sorted by access time.  The entries and using the hash table to jump to an 
entry when we need to evict it.

%Hey, no timestamps!

% Insert figure for O(1) LRU and hash table

In a nutshell, our LRU implementation uses a doubly linked list and utilize the 
hash table to jump to the element (instead of traversing the list linearly).
This design allows us to do all of the following action in constant time:

\begin{itemize}
	\item Insert a new entry to the LRU list
	\item Evict the LRU entry
	\item Update an entry's access time (i.e. mark it as MRU)
	\item Remove an arbitrary entry
\end{itemize}

Lets explain these fields a bit:

\begin{description}
	\item[lru:] Obviously, it's the least recently used entry. It can be 
		considered as the one end of the doubly linked list.
	\item[mru:] The entry that has just been used. It can be considered as 
		the other end of the doubly-linked list
	\item[younger:] This entry-specific field points to an entry used right 
		after our entry was used.
	\item[older:] Same as "younger", it points to the entry that has been 
		used right before our entry was used.
\end{description}

Finally, as we have explained in Section \ref{sec:xcache-evict-design}, the 
eviction internals should normally not bother the user. However, if the user 
wants to, \xcache provides the exposes the following functions:

\begin{description}
	\item[xcache\_evict\_lru:] The name says it all, it evicts the recently 
		used item.
	\item[xcache\_peek\_and\_get\_lru:] This function allows the user to 
		atomically take a peek on the Least Recently Used entry and also 
		update its refcount.
\end{description}

\subsection{Concurrency control}\label{sec:conc-imp}

\paragraph{Locking}\label{par:lock}

\paragraph{Reference counting}\label{par:refcount-imp}

The refcount model in xcache should be familiar to most people:

% Turn this to figure
\begin{itemize}
	\item When an entry is inserted in cache, the cache holds a reference 
		for it (ref = 1).
	\item Whenever a new lookup for this cache entry succeeds, the reference 
		is increased by 1 (ref++)
	\item When the request that has issued the lookup has finished with an 
		entry, the reference is decreased by 1. (ref--)
	\item When a cache entry is evicted by cache, the its ref is decreased 
		by 1. (ref--)
\end{itemize}

Some common refcount cases are:

\begin{itemize}
	\item active entry with pending jobs (ref > 1)
	\item active entry with no pending jobs (ref = 1)
	\item evicted entry with pending jobs (ref > 0)
	\item evicted entry with no pending jobs (ref = 0)
\end{itemize}

\begin{table}[tbp]
	\centering
	\begin{tabular}{ | l | l | }
		\hline
		Case & Refcount \\ \hline \hline
		active entry with pending jobs & ref > 1 \\ \hline
		active entry with no pending jobs & ref = 1 \\ \hline
		evicted entry with pending jobs & ref > 0 \\ \hline
		evicted entry with no pending jobs & ref = 0 \\ \hline
	\end{tabular}
	\caption{Reference counting of xcache}
	\label{tab:refcount}
\end{table}

and, as always, the entry is freed only when its ref = 0.

\subsection{Event hooks}

The hooks that xcache provides to users are:

\begin{itemize}
	\item on\_ init: called on cache entry initialization.
	\item on\_put: called when the last reference to the cache entry is put
	\item on\_evict: called when a cache entry is evicted.
	\item on\_node\_init: called on initial node preparation.
	\item post\_evict: called after an eviction has occurred, with cache  
		lock held.
	\item on\_free: called when a cache entry is freed.
	\item on\_finalize: called to hint the user that the cache entry's ref 
		has dropped to zero.
	\item on\_reinsert: called when a cache entry has been in cache
\end{itemize}


\section{Implementation of cached}\label{sec:cached-imp}

The cached structure is the following:

\ccode{Main cached struct}{cached.h}

We will briefly comment on the less important entries:

\begin{description}
	\item[*cache:]
		This is the connection between cached and xcache. The xcache struct is 
		stored here.
	\item[total\_size:]
		T
\end{description}

and the cached entries are the following

\ccode{Cahed entry struct}{ce.h}

\section{Bucket pool}

And the bucket implementation is the following:

\ccode{Bucket implementation}{bucket.h}

\subsection{Bucket/Object states}

Every object has a state, which is set atomically by threads. The state list is
the following:

\begin{itemize}
	\item READY: the object is ready to be used
	\item FLUSHING: the object is flushing its dirty buckets
	\item DELETING: there is a delete request that has been sent to the 
		blocker for this object
	\item INVALIDATED: the object has been deleted
	\item FAILED: something went very wrong with this object
\end{itemize}

Also, object buckets have their own states too. These are divided in allocation 
states:

\begin{itemize}
	\item FREE: the bucket has not been touched or has been flushed
	\item CLAIMED: the bucket has been claimed
\end{itemize}

and data states:

\begin{itemize}
	\item INVALID: the same as empty
	\item LOADING: there is a pending read to blocker for this bucket
	\item VALID: the bucket is clean and can be read
	\item DIRTY: the bucket can be read but its contents have not been
		written to the underlying storage
	\item WRITING: there is a pending write to blocker for this bucket
\end{itemize}

Also, for cios we have the following:

\begin{itemize}
	\item FAILED: at least one of the cio request(s) has failed
	\item ACCEPTED: normal mode
	\item READING: at least one of the cio request(s) is pending a read
	\item WRITING: at least one of the cio request(s) is pending a write
	\item SERVED: all requests have been served
\end{itemize}


Finally, for every object there are bucket state counters, which are increased/
decreased when a bucket state is changed. These counters give us an O(1)
glimpse to the bucket states of an object.


